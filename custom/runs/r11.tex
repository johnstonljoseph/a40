identity with params that worked for piecewise
and the new data sampling
and 16 bit activations
we'll see within 20 mins if it's going to budge at all. 

CHOSEN_ACTIVATION = IdentityActivation
# GATE_UP_QUANTIZER = QuantLinearWithScales
# DOWN_QUANTIZER = QuantLinearWithScales
GATE_UP_QUANTIZER = QuantLinearWithWeights
DOWN_QUANTIZER = QuantLinearWithWeights

@dataclass
class Config:
    batch_size: int = 8
    seq_len: int = 1024
    accumulate_steps: int = 16
    lr: float = 8e-5
    device: str = "cuda"
    dtype: str = "bfloat16"
    base_path: str = "/workspace/.hf_home/hub/models--allenai--Olmo-3-7B-Think"
    output_dir: str = str(DIR.parent / "checkpoints" / "student_final")
    dataset_sft: Optional[str] = "allenai/Dolci-Think-SFT-7B"
    dataset_dpo: Optional[str] = "allenai/Dolci-Think-DPO-7B"
    dataset_rl: Optional[str] = None
    # "allenai/Dolci-Think-RL-7B"
    dataset_ratio_sft: float = 0.9
    dataset_ratio_dpo: float = 0.1
    dataset_ratio_rl: float = 0.0
    shuffle_buffer_size: int = 10000
    seed: int = 42
    num_workers: int = 1
    compile: bool = True
    blend_steps: int = 20
    kl_threshold: float = 0.06
    hidden_mse_weight: float = 2.0
    kl_weight: float = 1.0
    weight_decay: float = 0.05
    act_fn_lr_mult: float = 5.0
    log_act_s_lr_mult: float = 20.0
    log_diag_s_lr_mult: float = 10.0
    log_weight_s_lr_mult: float = 1.0



distill:   5%|█▍                           | 32/640 [07:05<2:14:46, 13.30s/it, kl=0.0800, ema_kl=0.0320, ema_mse=0.0006, blend=0.050, base_lr=8.00e-05, step=1, top1=0.910, flip=0.090]
distill:  10%|██▊                         | 64/640 [12:34<1:47:54, 11.24s/it, kl=0.0730, ema_kl=0.0639, ema_mse=0.0024, blend=0.100, base_lr=8.00e-05, step=16, top1=0.920, flip=0.080]

distill:  20%|█████▍                     | 128/640 [24:08<1:10:30,  8.26s/it, kl=0.0615, ema_kl=0.0613, ema_mse=0.0043, blend=0.200, base_lr=8.00e-05, step=39, distill:  20%|▏| 128/640 [24:43<1:10:30,  8.26s/it, kl=0.0582, ema_kl=0.0601, distill:  35%|████████████████████████████▎                                                    | 224/640 [53:02<1:07:59,  9.81s/it, kl=0.0643, ema_kl=0.0628, ema_distill:  35%|▎| 224/640 [53:17<1:07:59,  9.81s/it, kl=0.0714, ema_kl=0.0662distill:  45%|███████████████████████████████████▌                                           | 288/640 [1:16:54<1:31:12, 15.55s/it, kl=0.1339, ema_kl=0.1391, ema_mse=0.0078, blend=0.450, base_lr=8.00e-05, step=200, top1=0.900, flip=0.100]

ok giving up since KL shot back up, and hasn't come down. that's not a good sign.